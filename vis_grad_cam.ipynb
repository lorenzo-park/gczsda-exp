{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad-CAM을 찍어볼 데이터셋\n",
    "target_dataset_name = \"exp8\" \n",
    "# Source only 모델 (No domain adaptation)\n",
    "MODEL_PATH = \"/root/dezsda/checkpoints/timm-mobilenet_v2-epoch=49-task=nexmon-val_loss=0.4483.ckpt\"\n",
    "# DANN 모델 (domain adaptation)\n",
    "MODEL_PATH_DANN = {\n",
    "    \"exp2\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=0.7519.ckpt\",\n",
    "    \"exp3\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=0.7335.ckpt\",\n",
    "    \"exp4\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=0.8891.ckpt\",\n",
    "    \"exp5\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=1.7659.ckpt\",\n",
    "    \"exp6\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=1.2919.ckpt\",\n",
    "    \"exp7\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=1.0723.ckpt\",\n",
    "    \"exp8\": \"/root/dezsda/checkpoints/dann-mobilenet_v2-epoch=49-task=nexmon-val_loss_tgt=1.3905.ckpt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.etc import Flatten\n",
    "from omegaconf import open_dict\n",
    "from dataset.nexmon import NexmonDataset\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "# from skimage.transform import resize\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from grad_cam import GradCam,GuidedBackpropReLUModel,show_cams,get_cam,show_gbs,preprocess_image\n",
    "from hydra import initialize_config_dir, compose\n",
    "from pl_module.timm import LitTimm\n",
    "from pl_module.dann import LitDANN\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=\"/root/dezsda\"):\n",
    "    config = compose(config_name=\"common.yaml\", overrides=[\"config=timm\", \"channels=3\"])\n",
    "    with open_dict(config):\n",
    "        config.num_classes = 7\n",
    "        config.num_test_sets = 1\n",
    "# model = models.vgg19(pretrained=True)\n",
    "pl_model = LitTimm.load_from_checkpoint(MODEL_PATH, config=config)\n",
    "model = nn.Sequential(\n",
    "    pl_model.model.feature_extractor,\n",
    "    pl_model.model.global_pool,\n",
    "    Flatten(),\n",
    "    pl_model.model.head,\n",
    ")\n",
    "\n",
    "with initialize_config_dir(config_dir=\"/root/dezsda\"):\n",
    "    config = compose(config_name=\"common.yaml\", overrides=[\"config=dann\", \"channels=3\"])\n",
    "    with open_dict(config):\n",
    "        config.num_classes = 7\n",
    "        config.num_test_sets = 1\n",
    "        config.batch_size = 16\n",
    "pl_model_dann = LitDANN.load_from_checkpoint(MODEL_PATH_DANN[target_dataset_name], config=config)\n",
    "model_dann = nn.Sequential(\n",
    "    pl_model_dann.model.feature_extractor,\n",
    "    pl_model_dann.model.global_pool,\n",
    "    Flatten(),\n",
    "    pl_model_dann.model.head,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "# transform = A.Compose([\n",
    "#     # A.Resize(self.config.img_size, self.config.img_size),\n",
    "#     # A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = NexmonDataset(\n",
    "#     root=f\"/shared/lorenzo/data-tubuki-cache/exp1-cwt\",\n",
    "#     fold=config.fold_no,\n",
    "#     train=False,\n",
    "#     transform=transform,\n",
    "#     single_per_class=True,\n",
    "# )\n",
    "\n",
    "# grad_cam = GradCam(model=model, blob_name = 'features', target_layer_names=['18'], use_cuda=False)\n",
    "# # img = cv2.imread('temp.jpg', 1)\n",
    "# # img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "# # img = np.float32(img) / 255\n",
    "# # inputs = preprocess_image(img)\n",
    "# # If None, returns the map for the highest scoring category.\n",
    "# # Otherwise, targets the requested index.\n",
    "# for batch in test_dataset:\n",
    "#     inputs, targets = batch\n",
    "#     target_index = None\n",
    "#     mask_dic = grad_cam(inputs.unsqueeze(0), target_index)\n",
    "\n",
    "#     for layer, mask in mask_dic.items():\n",
    "#         plt.imshow(inputs.permute(1,2,0))\n",
    "#         cam = get_cam(mask)\n",
    "#         plt.imshow(cam, alpha=0.7)\n",
    "#         plt.title(test_dataset.classes[targets])\n",
    "#         plt.show()\n",
    "# # show_cams(inputs.permute(1,2,0), mask_dic, test_dataset.classes[targets])\n",
    "# # gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU6', use_cuda=False)\n",
    "# # show_gbs(inputs.unsqueeze(0), gb_model, target_index, mask_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     # A.Resize(self.config.img_size, self.config.img_size),\n",
    "#     # A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "# test_dataset = NexmonDataset(\n",
    "#     root=f\"/shared/lorenzo/data-tubuki-cache/exp1-cwt\",\n",
    "#     fold=config.fold_no,\n",
    "#     train=False,\n",
    "#     transform=transform,\n",
    "#     # single_per_class=True,\n",
    "# )\n",
    "\n",
    "# grad_cam = GradCam(model=model, blob_name = 'features', target_layer_names=['18'], use_cuda=True)\n",
    "# # img = cv2.imread('temp.jpg', 1)\n",
    "# # img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "# # img = np.float32(img) / 255\n",
    "# # inputs = preprocess_image(img)\n",
    "# # If None, returns the map for the highest scoring category.\n",
    "# # Otherwise, targets the requested index.\n",
    "# cam_by_label = {}\n",
    "# for batch in tqdm.tqdm(test_dataset):\n",
    "#     inputs, targets = batch\n",
    "#     target_index = None\n",
    "#     mask_dic = grad_cam(inputs.unsqueeze(0).to(\"cuda:0\"), target_index)\n",
    "\n",
    "#     for layer, mask in mask_dic.items():\n",
    "#         # plt.imshow(inputs.permute(1,2,0))\n",
    "#         cam = get_cam(mask)\n",
    "#         cam = (cam > 200).astype(float)\n",
    "#         # plt.imshow((cam > 200).astype(float))\n",
    "#         label = test_dataset.classes[targets]\n",
    "#         # plt.title(label)\n",
    "#         # plt.show()\n",
    "#         if label not in cam_by_label:\n",
    "#             cam_by_label[label] = [cam]\n",
    "#         else:\n",
    "#             cam_by_label[label].append(cam)\n",
    "            \n",
    "# for k, v in cam_by_label.items():\n",
    "#     plt.imshow(np.mean(v, axis=0))\n",
    "#     plt.title(k)\n",
    "#     plt.show()\n",
    "# # show_cams(inputs.permute(1,2,0), mask_dic, test_dataset.classes[targets])\n",
    "# # gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU6', use_cuda=False)\n",
    "# # show_gbs(inputs.unsqueeze(0), gb_model, target_index, mask_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14, 10)\n",
    "\n",
    "transform = A.Compose([\n",
    "    # A.Resize(self.config.img_size, self.config.img_size),\n",
    "    # A.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_dataset = NexmonDataset(\n",
    "    root=f\"/shared/lorenzo/data-tubuki-cache/{target_dataset_name}-cwt\",\n",
    "    fold=config.fold_no,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    single_per_class=True, # 각 클래스별로 하나씩만 결과 출력\n",
    ")\n",
    "\n",
    "grad_cam = GradCam(model=model, blob_name = 'features', target_layer_names=['18'], use_cuda=True)\n",
    "grad_cam_dann = GradCam(model=model_dann, blob_name = 'features', target_layer_names=['18'], use_cuda=True)\n",
    "# img = cv2.imread('temp.jpg', 1)\n",
    "# img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "# img = np.float32(img) / 255\n",
    "# inputs = preprocess_image(img)\n",
    "# If None, returns the map for the highest scoring category.\n",
    "# Otherwise, targets the requested index.\n",
    "for batch in test_dataset:\n",
    "    inputs, targets = batch\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs.unsqueeze(0), target_index)\n",
    "    mask_dic_dann = grad_cam_dann(inputs.unsqueeze(0), target_index)\n",
    "\n",
    "    for (_, mask), (_, mask_dann) in zip(mask_dic.items(), mask_dic_dann.items()):\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.imshow(inputs.permute(1,2,0))\n",
    "        cam = get_cam(mask)\n",
    "        ax1.imshow(cam, alpha=0.7)\n",
    "        \n",
    "        ax2.imshow(inputs.permute(1,2,0))\n",
    "        cam_dann = get_cam(mask_dann)\n",
    "        ax2.imshow(cam_dann, alpha=0.7)\n",
    "        \n",
    "        plt.title(test_dataset.classes[targets])\n",
    "        plt.savefig(f\"output_img_tubuki/{target_dataset_name}_{test_dataset.classes[targets]}.png\")\n",
    "        plt.close()\n",
    "None\n",
    "# show_cams(inputs.permute(1,2,0), mask_dic, test_dataset.classes[targets])\n",
    "# gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU6', use_cuda=False)\n",
    "# show_gbs(inputs.unsqueeze(0), gb_model, target_index, mask_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a01d51d017b7a745f6c1da9c6218fc4465806786256aaaa00ff28e587d8b1cd4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "name": "python3710jvsc74a57bd062abdba18a5af63216677fd9809182d4d30d0131cee927ee8b1e01ef771e0b25"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}