{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 10\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(10)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from dataset.digit import ChanDup, CENDataset\n",
    "from pl_module.gcada import LitGCADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCADAConfig:\n",
    "    checkpoint_filename = [\n",
    "        \"gcada-lenet-epoch=00-task=digit-val_loss_tgt=3.9711.ckpt\",\n",
    "        # \"gcada-lenet-epoch=02-task=digit-val_loss=0.0000.ckpt\",\n",
    "        # \"gcada-lenet-epoch=04-task=digit-val_loss=0.0000.ckpt\",\n",
    "        # \"gcada-lenet-epoch=06-task=digit-val_loss=0.0000.ckpt\",\n",
    "    ]\n",
    "    lambda_noise: None\n",
    "    device=\"cuda:1\"\n",
    "    \n",
    "    root=\"/shared/lorenzo/mnist-zsda/MNIST_G\"\n",
    "    root_tgt=\"/shared/lorenzo/mnist-zsda/MNIST_C\"\n",
    "    \n",
    "    model_name=\"gcada\"\n",
    "    backbone_name=\"lenet\"\n",
    "    \n",
    "    root_tgt_train=\"/shared/lorenzo/mnist-zsda/FashionMNIST_C\"\n",
    "    num_blocks=9\n",
    "    hidden_dim_dsc=64\n",
    "    lambda_idt=1.0\n",
    "    lambda_sem=0.0\n",
    "    transformation=\"rotate\"\n",
    "    beta1=0.5\n",
    "    pretrained=\"/root/dezsda/checkpoints/timm-lenet-epoch=03-task=digit-val_loss=0.0297.ckpt\"\n",
    "    fix_block_up=False\n",
    "    lambda_sem_idt=10.0\n",
    "    sem_idt_per_epoch=1\n",
    "\n",
    "    lr = 1e-3\n",
    "    optimizer = \"adam\"\n",
    "    batch_size = 64\n",
    "    max_epochs = 50\n",
    "    grad_accum = 1\n",
    "    es_patience = None\n",
    "    task=\"digit\"\n",
    "    img_size = 28\n",
    "    fold_no = 0\n",
    "    num_workers = 8\n",
    "    channels = 3\n",
    "    logger = True\n",
    "    seed = 42\n",
    "    project = \"csi-har\"\n",
    "    checkpoint_dir = \"/root/dezsda/checkpoints\"\n",
    "    gpus = 1\n",
    "    num_classes=10\n",
    "    num_test_sets=4\n",
    "\n",
    "    assert root.split(\"/\")[-1].split(\"_\")[0] == root_tgt.split(\"/\")[-1].split(\"_\")[0]\n",
    "    translated_dir=f\"/shared/lorenzo/mnist-zsda/{root.split('/')[-1].split('_')[0]}_{root.split('/')[-1].split('_')[-1]}{root_tgt.split('/')[-1].split('_')[-1]}\"\n",
    "    \n",
    "config = GCADAConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 937/937 [00:07<00:00, 118.94it/s]\n",
      "100%|██████████| 937/937 [00:07<00:00, 126.09it/s]\n",
      "100%|██████████| 937/937 [00:07<00:00, 124.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1440 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cf in config.checkpoint_filename:\n",
    "    pl_model = LitGCADA.load_from_checkpoint(f\"./checkpoints/{cf}\", config=config)\n",
    "    model = pl_model.model\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.Resize(32),\n",
    "        transforms.CenterCrop((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ChanDup(),\n",
    "    ])\n",
    "\n",
    "    dataset = CENDataset(root=config.root_tgt_train, train=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size,\n",
    "                            shuffle=True, pin_memory=True, \n",
    "                            num_workers=config.num_workers, drop_last=True)\n",
    "\n",
    "    model = model.to(config.device)\n",
    "    translated_inputs_tgt = None\n",
    "    translated_targets_tgt = None\n",
    "    for batch in tqdm(dataloader):\n",
    "        inputs_src, targets_src = batch\n",
    "        inputs_src = inputs_src.to(config.device)\n",
    "        targets_src = targets_src.to(config.device)\n",
    "\n",
    "        outputs = model.get_feature(inputs_src)\n",
    "\n",
    "        if translated_inputs_tgt is not None:\n",
    "            translated_inputs_tgt = torch.cat([outputs.detach(), translated_inputs_tgt], dim=0)\n",
    "            translated_targets_tgt = torch.cat([targets_src.detach(), translated_targets_tgt], dim=0)\n",
    "        else:\n",
    "            translated_inputs_tgt = outputs\n",
    "            translated_targets_tgt = targets_src\n",
    "\n",
    "        del outputs\n",
    "        del targets_src\n",
    "\n",
    "    dataset = datasets.MNIST(root=config.root, train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size,\n",
    "                            shuffle=True, pin_memory=True, \n",
    "                            num_workers=config.num_workers, drop_last=True)\n",
    "\n",
    "    model = model.to(config.device)\n",
    "    translated_inputs_src = None\n",
    "    translated_targets_src = None\n",
    "    for batch in tqdm(dataloader):\n",
    "        inputs_src, targets_src = batch\n",
    "        inputs_src = inputs_src.to(config.device)\n",
    "        targets_src = targets_src.to(config.device)\n",
    "\n",
    "        outputs = model.get_feature(inputs_src)\n",
    "\n",
    "        if translated_inputs_src is not None:\n",
    "            translated_inputs_src = torch.cat([outputs.detach(), translated_inputs_src], dim=0)\n",
    "            translated_targets_src = torch.cat([targets_src.detach(), translated_targets_src], dim=0)\n",
    "        else:\n",
    "            translated_inputs_src = outputs\n",
    "            translated_targets_src = targets_src\n",
    "\n",
    "        del outputs\n",
    "        del targets_src\n",
    "\n",
    "    dataset = CENDataset(root=config.root_tgt, train=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size,\n",
    "                            shuffle=True, pin_memory=True, \n",
    "                            num_workers=config.num_workers, drop_last=True)\n",
    "\n",
    "    model = model.to(config.device)\n",
    "    translated_inputs_tgt_test = None\n",
    "    translated_targets_tgt_test = None\n",
    "    for batch in tqdm(dataloader):\n",
    "        inputs_src, targets_src = batch\n",
    "        inputs_src = inputs_src.to(config.device)\n",
    "        targets_src = targets_src.to(config.device)\n",
    "\n",
    "        outputs = model.get_feature(inputs_src)\n",
    "\n",
    "        if translated_inputs_tgt_test is not None:\n",
    "            translated_inputs_tgt_test = torch.cat([outputs.detach(), translated_inputs_tgt_test], dim=0)\n",
    "            translated_targets_tgt_test = torch.cat([targets_src.detach(), translated_targets_tgt_test], dim=0)\n",
    "        else:\n",
    "            translated_inputs_tgt_test = outputs\n",
    "            translated_targets_tgt_test = targets_src\n",
    "\n",
    "        del outputs\n",
    "        del targets_src\n",
    "\n",
    "    X_tgt = translated_inputs_tgt.cpu().detach().numpy()[:1000]\n",
    "    X_src = translated_inputs_src.cpu().detach().numpy()[:1000]\n",
    "    X_tgt_test = translated_inputs_tgt_test.cpu().detach().numpy()[:1000]\n",
    "\n",
    "    _ = translated_targets_tgt.cpu().detach().numpy()[:1000].astype(str).tolist()\n",
    "    y_src = translated_targets_src.cpu().detach().numpy()[:1000].astype(str).tolist()\n",
    "    y_tgt_test = translated_targets_tgt_test.cpu().detach().numpy()[:1000].astype(str).tolist()\n",
    "\n",
    "    X = np.concatenate([X_tgt, X_src, X_tgt_test], axis=0)\n",
    "    X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                    init='random').fit_transform(X)\n",
    "\n",
    "    df = pd.DataFrame(X_embedded)\n",
    "    df[\"group\"] = [\"tgt_train (FashionMNIST_C)\"] * 1000 + [\"src_train (MNIST_G)\"] * 1000 +[\"tgt_test (MNIST_C)\"] * 1000\n",
    "    df[\"target\"] = [\"-\"] * 1000 + y_src + y_tgt_test\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    sns.scatterplot(data=df, x=0, y=1, hue=\"group\", s=400)\n",
    "    plt.legend(markerscale=3, fontsize=18)\n",
    "    plt.savefig(f\"{cf}.group.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "    sns.scatterplot(data=df, x=0, y=1, hue=\"target\", s=400, style=\"group\")\n",
    "    plt.legend(markerscale=3, fontsize=18)\n",
    "    plt.savefig(f\"{cf}.class.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "name": "python3710jvsc74a57bd062abdba18a5af63216677fd9809182d4d30d0131cee927ee8b1e01ef771e0b25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "62abdba18a5af63216677fd9809182d4d30d0131cee927ee8b1e01ef771e0b25"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}